# RAG runtime mode: real | synthetic
RAG_EVAL_EXECUTION_MODE=real
# Safety guard: keep synthetic mode disabled in production.
RAG_ALLOW_SYNTHETIC_MODE=false

# OpenAI-compatible endpoint settings
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_BASE_URL=https://api.openai.com/v1

# Model selection
OPENAI_CHAT_MODEL=gpt-4.1-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_VERIFIER_MODEL=gpt-4.1-mini

# Runtime controls
RAG_REQUEST_TIMEOUT_SEC=120
RAG_MAX_GENERATION_TOKENS=700
RAG_MAX_CONTEXT_CHARS=1400
RAG_EMBEDDING_BATCH_SIZE=48
RAG_TOP_CANDIDATE_MULTIPLIER=5
RAG_MAX_RERANK_CANDIDATES=20
RAG_MAX_VERIFIER_CLAIMS=8

# Optional LogicRAG integration service (Docker compose sets this automatically for backend)
LOGICRAG_SERVICE_URL=
LOGICRAG_TIMEOUT_SEC=180
LOGICRAG_MAX_ROUNDS=4
LOGICRAG_FILTER_REPEATS=true

# Optional comma-separated CORS allowlist additions for non-local frontend origins
RAG_EVAL_CORS_ALLOW_ORIGINS=
